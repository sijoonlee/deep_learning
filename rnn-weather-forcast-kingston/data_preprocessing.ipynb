{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the weather data\n",
    "1) Download the weather data from climate.weather.gc.ca  \n",
    "2) Mimick the naming convention of the files and make them as array  \n",
    "3) Find missing data  \n",
    "4) Iterate the array to open files in time order and Create dataset  \n",
    "5) Fill the missing data in dataset by Interpolation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download the data files\n",
    "Source : http://climate.weather.gc.ca  \n",
    "Desc: Hourly Weather Data from Jan. 2015 to July. 2018 in Kingston  \n",
    "Station : Kingston climate, Ontario, Canada  \n",
    "Station ID: 47267  \n",
    "\n",
    "\n",
    "**Linux Command to get weather data**\n",
    "\n",
    "for year in `seq 2015 2018`;do for month in `seq 1 12`;do wget --content-disposition \"http://climate.weather.gc.ca/climate_data/bulk_data_e.html?format=csv&stationID=47267&Year=${year}&Month=${month}&Day=14&timeframe=1&submit= Download+Data\" ;done;done\n",
    "  \n",
    "for year in `seq 2019 2019`;do for month in `seq 1 7`;do wget --content-disposition \"http://climate.weather.gc.ca/climate_data/bulk_data_e.html?format=csv&stationID=47267&Year=${year}&Month=${month}&Day=14&timeframe=1&submit= Download+Data\" ;done;done\n",
    "\n",
    "**To see the detail of the query, please refer below**\n",
    "\n",
    "https://drive.google.com/drive/folders/1WJCDEU34c60IfOnG4rv5EPZ4IhhW9vZH  \n",
    "\n",
    "http://climate.weather.gc.ca/climate_data/hourly_data_e.html?hlyRange=2008-07-15%7C2019-08-05&dlyRange=2008-07-15%7C2019-08-05&mlyRange=%7C&StationID=47267&Prov=ON&urlExtension=_e.html&searchType=stnProv&optLimit=yearRange&StartYear=2019&EndYear=2019&selRowPerPage=25&Line=77&Month=8&Day=5&lstProvince=ON&timeframe=1&Year=2019\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set up the array of file names\n",
    "\n",
    "Using the naming convention, set up the file name array  \n",
    "\n",
    "e.g.) Jan. 2015 data file's name  =  \"eng-hourly-01012015-01312015.csv\"  \n",
    "which means data between 01-01-2015 and 01-31-2015\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eng-hourly-01012015-01312015.csv', 'eng-hourly-02012015-02282015.csv', 'eng-hourly-03012015-03312015.csv', 'eng-hourly-04012015-04302015.csv', 'eng-hourly-05012015-05312015.csv', 'eng-hourly-06012015-06302015.csv', 'eng-hourly-07012015-07312015.csv', 'eng-hourly-08012015-08312015.csv', 'eng-hourly-09012015-09302015.csv', 'eng-hourly-10012015-10312015.csv', 'eng-hourly-11012015-11302015.csv', 'eng-hourly-12012015-12312015.csv', 'eng-hourly-01012016-01312016.csv', 'eng-hourly-02012016-02292016.csv', 'eng-hourly-03012016-03312016.csv', 'eng-hourly-04012016-04302016.csv', 'eng-hourly-05012016-05312016.csv', 'eng-hourly-06012016-06302016.csv', 'eng-hourly-07012016-07312016.csv', 'eng-hourly-08012016-08312016.csv', 'eng-hourly-09012016-09302016.csv', 'eng-hourly-10012016-10312016.csv', 'eng-hourly-11012016-11302016.csv', 'eng-hourly-12012016-12312016.csv', 'eng-hourly-01012017-01312017.csv', 'eng-hourly-02012017-02282017.csv', 'eng-hourly-03012017-03312017.csv', 'eng-hourly-04012017-04302017.csv', 'eng-hourly-05012017-05312017.csv', 'eng-hourly-06012017-06302017.csv', 'eng-hourly-07012017-07312017.csv', 'eng-hourly-08012017-08312017.csv', 'eng-hourly-09012017-09302017.csv', 'eng-hourly-10012017-10312017.csv', 'eng-hourly-11012017-11302017.csv', 'eng-hourly-12012017-12312017.csv', 'eng-hourly-01012018-01312018.csv', 'eng-hourly-02012018-02282018.csv', 'eng-hourly-03012018-03312018.csv', 'eng-hourly-04012018-04302018.csv', 'eng-hourly-05012018-05312018.csv', 'eng-hourly-06012018-06302018.csv', 'eng-hourly-07012018-07312018.csv', 'eng-hourly-08012018-08312018.csv', 'eng-hourly-09012018-09302018.csv', 'eng-hourly-10012018-10312018.csv', 'eng-hourly-11012018-11302018.csv', 'eng-hourly-12012018-12312018.csv', 'eng-hourly-01012019-01312019.csv', 'eng-hourly-02012019-02282019.csv', 'eng-hourly-03012019-03312019.csv', 'eng-hourly-04012019-04302019.csv', 'eng-hourly-05012019-05312019.csv', 'eng-hourly-06012019-06302019.csv', 'eng-hourly-07012019-07312019.csv']\n"
     ]
    }
   ],
   "source": [
    "import calendar\n",
    "\n",
    "years = [2015,2016,2017,2018]\n",
    "filenames = []\n",
    "\n",
    "for year in years:\n",
    "    for month in range(1,13):\n",
    "        filename = 'eng-hourly-{month:02d}01{year}-{month:02d}{last:02d}{year}.csv'.format(month=month, year=year, last=calendar.monthrange(year, month)[1])\n",
    "        filenames.append(filename)\n",
    "\n",
    "years = [2019]\n",
    "for year in years:\n",
    "    for month in range(1, 8):\n",
    "        filename = 'eng-hourly-{month:02d}01{year}-{month:02d}{last:02d}{year}.csv'.format(month=month, year=year, last=calendar.monthrange(year, month)[1])\n",
    "        filenames.append(filename)\n",
    "        \n",
    "print(filenames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-26 06:00,2017,11,26,06:00\n",
      "\n",
      "2017-11-26 07:00,2017,11,26,07:00\n",
      "\n",
      "2017-11-26 08:00,2017,11,26,08:00\n",
      "\n",
      "2017-11-26 09:00,2017,11,26,09:00\n",
      "\n",
      "2017-11-26 10:00,2017,11,26,10:00\n",
      "\n",
      "550\n"
     ]
    }
   ],
   "source": [
    "def find_missing_data(filenames):\n",
    "    \n",
    "    \n",
    "    raw_file = open(filenames[0], \"r\")\n",
    "    raw_data = raw_file.readlines()[16:]\n",
    "    raw_file.close()\n",
    "    \n",
    "    for index in range(1, len(filenames)):\n",
    "        raw_file = open(filenames[index], \"r\")\n",
    "        raw_data = raw_data + raw_file.readlines()[16:]\n",
    "        raw_file.close()\n",
    "\n",
    "    new_filename = \"missing_data.csv\"\n",
    "    f = open(new_filename, \"w\")\n",
    "    output = []\n",
    "    for item in raw_data:\n",
    "        if item.count(\",\") is not 23: # if full data, it is supposed to have 23 of , (seperator)\n",
    "            output.append(item.replace(\"\\\"\", \"\"))\n",
    "    f.writelines(output)\n",
    "    f.close()\n",
    "                          \n",
    "find_missing_data(filenames)\n",
    "\n",
    "# some large chunk of missing data were found. \n",
    "# e.g.) 2017-11-26 ~ 2017-12-06\n",
    "# e.g.) 2018-04-23 ~ 2018-04-27\n",
    "\n",
    "missing_data_file = open(\"missing_data.csv\", \"r\")\n",
    "missing_data = missing_data_file.readlines()\n",
    "missing_data_file.close()\n",
    "for item in missing_data[190:195]:\n",
    "    print(item)\n",
    "    \n",
    "print(len(missing_data)) # total 550 days have missing information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create Dataset (Pandas Dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40152, 24)\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "\n",
    "dataset = read_csv(filenames[0], skiprows = 15, header = 0)\n",
    "for count in range(1, len(filenames)):\n",
    "    dataset = pd.concat([dataset, read_csv(filenames[count], skiprows = 15, header = 0)])\n",
    "\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unnecessary columns in raw data\n",
    "to_be_deleted = [1, 2, 3, 4, 6, 8, 10, 12, 14, 15, 16, 18, 19, 20, 21, 22, 23] \n",
    "dataset = dataset.drop(dataset.columns[to_be_deleted], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Temp (°C)  Dew Point Temp (°C)  Rel Hum (%)  \\\n",
      "Date/Time                                                       \n",
      "2015-01-16 20:00      -14.1                -22.2         50.0   \n",
      "2015-01-16 21:00      -15.8                -22.9         54.0   \n",
      "2015-01-16 22:00        NaN                  NaN          NaN   \n",
      "2015-01-16 23:00        NaN                  NaN          NaN   \n",
      "2015-01-17 00:00        NaN                  NaN          NaN   \n",
      "2015-01-17 01:00        NaN                  NaN          NaN   \n",
      "2015-01-17 02:00        NaN                  NaN          NaN   \n",
      "2015-01-17 03:00        NaN                  NaN          NaN   \n",
      "2015-01-17 04:00        NaN                  NaN          NaN   \n",
      "2015-01-17 05:00        NaN                  NaN          NaN   \n",
      "2015-01-17 06:00        NaN                  NaN          NaN   \n",
      "2015-01-17 07:00        NaN                  NaN          NaN   \n",
      "2015-01-17 08:00        NaN                  NaN          NaN   \n",
      "2015-01-17 09:00        NaN                  NaN          NaN   \n",
      "2015-01-17 10:00      -18.0                -22.8         66.0   \n",
      "\n",
      "                  Wind Dir (10s deg)  Wind Spd (km/h)  Stn Press (kPa)  \n",
      "Date/Time                                                               \n",
      "2015-01-16 20:00                31.0             10.0           101.25  \n",
      "2015-01-16 21:00                33.0             11.0           101.34  \n",
      "2015-01-16 22:00                 NaN              NaN              NaN  \n",
      "2015-01-16 23:00                 NaN              NaN              NaN  \n",
      "2015-01-17 00:00                 NaN              NaN              NaN  \n",
      "2015-01-17 01:00                 NaN              NaN              NaN  \n",
      "2015-01-17 02:00                 NaN              NaN              NaN  \n",
      "2015-01-17 03:00                 NaN              NaN              NaN  \n",
      "2015-01-17 04:00                 NaN              NaN              NaN  \n",
      "2015-01-17 05:00                 NaN              NaN              NaN  \n",
      "2015-01-17 06:00                 NaN              NaN              NaN  \n",
      "2015-01-17 07:00                 NaN              NaN              NaN  \n",
      "2015-01-17 08:00                 NaN              NaN              NaN  \n",
      "2015-01-17 09:00                 NaN              NaN              NaN  \n",
      "2015-01-17 10:00                 7.0             13.0           101.67  \n"
     ]
    }
   ],
   "source": [
    "# set Date/Time colum to index\n",
    "\n",
    "# https://appdividend.com/2019/01/26/pandas-set-index-example-python-set_index-tutorial/\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.set_index.html\n",
    "\n",
    "dataset.set_index(dataset.columns[0], inplace=True)\n",
    "\n",
    "# missing data\n",
    "print(dataset[380:395]) # missing data at row 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Temp (°C)              560\n",
       "Dew Point Temp (°C)    551\n",
       "Rel Hum (%)            550\n",
       "Wind Dir (10s deg)     770\n",
       "Wind Spd (km/h)        550\n",
       "Stn Press (kPa)        551\n",
       "dtype: int64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many missing data are there\n",
    "dataset.isnull().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Fill the missing data\n",
    "\n",
    "I'v considered which one to use, Fillna() or Interpolate()  \n",
    "But for this time, I chose Interpolate() since the data is time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pandas - fillna method**\n",
    "\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/03.04-missing-values.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.fillna(dataset.mean(), inplace=True)\n",
    "# dataset.fillna(method='ffill', inplace = True)\n",
    "# dataset.fillna(method='bfill', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pandas - Interpolation**\n",
    "\n",
    "https://www.geeksforgeeks.org/python-pandas-dataframe-interpolate/  \n",
    "https://stackoverflow.com/questions/34934511/cannot-interpolate-dataframe-even-if-most-of-the-data-is-filled  \n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#interpolation  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Temp (°C)  Dew Point Temp (°C)  Rel Hum (%)  \\\n",
      "Date/Time                                                       \n",
      "2015-01-16 20:00 -14.100000           -22.200000    50.000000   \n",
      "2015-01-16 21:00 -15.800000           -22.900000    54.000000   \n",
      "2015-01-16 22:00 -15.969231           -22.892308    54.923077   \n",
      "2015-01-16 23:00 -16.138462           -22.884615    55.846154   \n",
      "2015-01-17 00:00 -16.307692           -22.876923    56.769231   \n",
      "2015-01-17 01:00 -16.476923           -22.869231    57.692308   \n",
      "2015-01-17 02:00 -16.646154           -22.861538    58.615385   \n",
      "2015-01-17 03:00 -16.815385           -22.853846    59.538462   \n",
      "2015-01-17 04:00 -16.984615           -22.846154    60.461538   \n",
      "2015-01-17 05:00 -17.153846           -22.838462    61.384615   \n",
      "2015-01-17 06:00 -17.323077           -22.830769    62.307692   \n",
      "2015-01-17 07:00 -17.492308           -22.823077    63.230769   \n",
      "2015-01-17 08:00 -17.661538           -22.815385    64.153846   \n",
      "2015-01-17 09:00 -17.830769           -22.807692    65.076923   \n",
      "2015-01-17 10:00 -18.000000           -22.800000    66.000000   \n",
      "\n",
      "                  Wind Dir (10s deg)  Wind Spd (km/h)  Stn Press (kPa)  \n",
      "Date/Time                                                               \n",
      "2015-01-16 20:00                31.0        10.000000       101.250000  \n",
      "2015-01-16 21:00                33.0        11.000000       101.340000  \n",
      "2015-01-16 22:00                31.0        11.153846       101.365385  \n",
      "2015-01-16 23:00                29.0        11.307692       101.390769  \n",
      "2015-01-17 00:00                27.0        11.461538       101.416154  \n",
      "2015-01-17 01:00                25.0        11.615385       101.441538  \n",
      "2015-01-17 02:00                23.0        11.769231       101.466923  \n",
      "2015-01-17 03:00                21.0        11.923077       101.492308  \n",
      "2015-01-17 04:00                19.0        12.076923       101.517692  \n",
      "2015-01-17 05:00                17.0        12.230769       101.543077  \n",
      "2015-01-17 06:00                15.0        12.384615       101.568462  \n",
      "2015-01-17 07:00                13.0        12.538462       101.593846  \n",
      "2015-01-17 08:00                11.0        12.692308       101.619231  \n",
      "2015-01-17 09:00                 9.0        12.846154       101.644615  \n",
      "2015-01-17 10:00                 7.0        13.000000       101.670000  \n"
     ]
    }
   ],
   "source": [
    "# Interpolation\n",
    "dataset.interpolate(method='linear', limit_direction ='both', limit=500, inplace=True)\n",
    "print(dataset[380:395])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Temp (°C)              0\n",
       "Dew Point Temp (°C)    0\n",
       "Rel Hum (%)            0\n",
       "Wind Dir (10s deg)     0\n",
       "Wind Spd (km/h)        0\n",
       "Stn Press (kPa)        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum() # No N/A now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the processed data to .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv (r'export_data.csv', header=True) #Don't forget to add '.csv' at the end of the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make suer it's done properly\n",
    "dataset = read_csv('export_data.csv', header = 0)\n",
    "dataset.set_index(dataset.columns[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Temp (°C)  Dew Point Temp (°C)  Rel Hum (%)  \\\n",
      "Date/Time                                                       \n",
      "2015-01-01 00:00       -5.9                -11.8         63.0   \n",
      "2015-01-01 01:00       -5.9                -13.6         54.0   \n",
      "2015-01-01 02:00       -6.1                -14.2         53.0   \n",
      "2015-01-01 03:00       -5.8                -13.2         56.0   \n",
      "2015-01-01 04:00       -5.7                -11.9         62.0   \n",
      "\n",
      "                  Wind Dir (10s deg)  Wind Spd (km/h)  Stn Press (kPa)  \n",
      "Date/Time                                                               \n",
      "2015-01-01 00:00                26.0             28.0           100.21  \n",
      "2015-01-01 01:00                26.0             21.0           100.19  \n",
      "2015-01-01 02:00                26.0             27.0           100.17  \n",
      "2015-01-01 03:00                25.0             28.0           100.14  \n",
      "2015-01-01 04:00                25.0             24.0           100.14  \n",
      "                  Temp (°C)  Dew Point Temp (°C)  Rel Hum (%)  \\\n",
      "Date/Time                                                       \n",
      "2019-07-31 19:00       24.5                 16.5         61.0   \n",
      "2019-07-31 20:00       23.1                 16.8         67.0   \n",
      "2019-07-31 21:00       21.9                 18.1         79.0   \n",
      "2019-07-31 22:00       22.1                 14.3         61.0   \n",
      "2019-07-31 23:00       21.3                 12.8         58.0   \n",
      "\n",
      "                  Wind Dir (10s deg)  Wind Spd (km/h)  Stn Press (kPa)  \n",
      "Date/Time                                                               \n",
      "2019-07-31 19:00                28.0             11.0           100.58  \n",
      "2019-07-31 20:00                28.0              8.0           100.61  \n",
      "2019-07-31 21:00                33.0             11.0           100.67  \n",
      "2019-07-31 22:00                 2.0             11.0           100.69  \n",
      "2019-07-31 23:00                 1.0             10.0           100.72  \n"
     ]
    }
   ],
   "source": [
    "print(dataset[:5])\n",
    "print(dataset[-5:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
