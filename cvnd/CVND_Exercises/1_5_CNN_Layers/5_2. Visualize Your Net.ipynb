{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Classification\n",
    "---\n",
    "In this notebook, we define **and train** an CNN to classify images from the [Fashion-MNIST database](https://github.com/zalandoresearch/fashion-mnist)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the [data](http://pytorch.org/docs/master/torchvision/datasets.html)\n",
    "\n",
    "In this cell, we load in both **training and test** datasets from the FashionMNIST class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our basic libraries\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# data loading and transforming\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1]. \n",
    "# We transform them to Tensors for input into a CNN\n",
    "\n",
    "## Define a transform to read the data in as a tensor\n",
    "data_transform = transforms.ToTensor()\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = FashionMNIST(root='./data', train=True,\n",
    "                                   download=True, transform=data_transform)\n",
    "\n",
    "test_data = FashionMNIST(root='./data', train=False,\n",
    "                                  download=True, transform=data_transform)\n",
    "\n",
    "\n",
    "# Print out some stats about the training and test data\n",
    "print('Train data, number of images: ', len(train_data))\n",
    "print('Test data, number of images: ', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare data loaders, set the batch_size\n",
    "## TODO: you can try changing the batch_size to be larger or smaller\n",
    "## when you get to training your network, see how batch_size affects the loss\n",
    "batch_size = 20\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# specify the image classes\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize some training data\n",
    "\n",
    "This cell iterates over the training dataset, loading a random batch of image/label data, using `dataiter.next()`. It then plots the batch of images and labels in a `2 x batch_size/2` grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "    \n",
    "# obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy()\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(batch_size):\n",
    "    ax = fig.add_subplot(2, batch_size/2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    ax.set_title(classes[labels[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the network architecture\n",
    "\n",
    "The various layers that make up any neural network are documented, [here](http://pytorch.org/docs/master/nn.html). For a convolutional neural network, we'll use a simple series of layers:\n",
    "* Convolutional layers\n",
    "* Maxpooling layers\n",
    "* Fully-connected (linear) layers\n",
    "\n",
    "You are also encouraged to look at adding [dropout layers](http://pytorch.org/docs/stable/nn.html#dropout) to avoid overfitting this data.\n",
    "\n",
    "---\n",
    "\n",
    "### TODO: Define the Net\n",
    "\n",
    "Define the layers of your **best, saved model from the classification exercise** in the function `__init__` and define the feedforward behavior of that Net in the function `forward`. Defining the architecture here, will allow you to instantiate and load your best Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # 1 input image channel (grayscale), 10 output channels/feature maps\n",
    "        # 3x3 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(1, 10, 3)\n",
    "        \n",
    "        ## TODO: Define the rest of the layers:\n",
    "        # include another conv layer, maxpooling layers, and linear layers\n",
    "        # also consider adding a dropout layer to avoid overfitting\n",
    "        \n",
    "\n",
    "    ## TODO: define the feedforward behavior\n",
    "    def forward(self, x):\n",
    "        # one activated conv layer\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        # final output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a Trained, Saved Model\n",
    "\n",
    "To instantiate a trained model, you'll first instantiate a new `Net()` and then initialize it with a saved dictionary of parameters. This notebook needs to know the network architecture, as defined above, and once it knows what the \"Net\" class looks like, we can instantiate a model and load in an already trained network.\n",
    "\n",
    "You should have a trained net in `saved_models/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate your Net\n",
    "net = Net()\n",
    "\n",
    "# load the net parameters by name, uncomment the line below to load your model\n",
    "# net.load_state_dict(torch.load('saved_models/model_1.pt'))\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Visualization\n",
    "\n",
    "To see what your network has learned, make a plot of the learned image filter weights and the activation maps (for a given image) at each convolutional layer.\n",
    "\n",
    "### TODO: Visualize the learned filter weights and activation maps of the convolutional layers in your trained Net\n",
    "\n",
    "Choose a sample input image and apply the filters in every convolutional layer to that image to see the activation map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a reminder, here is how we got the weights in the first conv layer (conv1), before\n",
    "weights = net.conv1.weight.data\n",
    "w = weights.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Choose a filter from one of your trained convolutional layers; looking at these activations, what purpose do you think it plays? What kind of feature do you think it detects?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
